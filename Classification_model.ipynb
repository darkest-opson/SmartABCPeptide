{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GB8pL-hALuZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Superzchen/iFeature.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710hhxJSLurP",
        "outputId": "49084540-cb24-453e-9aec-7466aa747f08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'iFeature' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uo0TJGFLLu6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbpcKKMLLv-1",
        "outputId": "d02679a2-b585-4206-a35f-8ab335e292b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2024.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython==1.84"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JenjLOXeL2Mo",
        "outputId": "f703a323-fb60-4922-83da-75423262f5d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython==1.84 in /usr/local/lib/python3.11/dist-packages (1.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython==1.84) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8vEYT6L2Yr",
        "outputId": "06d8ca0d-80f1-445e-d1df-140861c7f6af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH5d3v5HL2di",
        "outputId": "4c0eee45-59df-4f16-8641-999bae4f8aac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_fasta(sequence, filename=\"peptide.fasta\", header=\">sequence\"):\n",
        "    lines = sequence.strip().split(\"\\n\")\n",
        "    if lines[0].startswith(\">\"):\n",
        "        fasta_content = sequence.strip()\n",
        "    else:\n",
        "        fasta_content = f\"{header}\\n{sequence.strip()}\"\n",
        "    with open(filename, \"w\") as fasta_file:\n",
        "        fasta_file.write(fasta_content)\n",
        "\n",
        "    return filename\n",
        "user_sequence = input(\"Enter the sequence: \").strip()\n",
        "saved_file = convert_to_fasta(user_sequence, \"peptide.fasta\")\n",
        "print(f\"FASTA file saved as: {saved_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5B8AHBSL_0O",
        "outputId": "cae0507c-ea72-47a8-9d3c-6c1508662da3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the sequence: MLCYPRADQ\n",
            "FASTA file saved as: peptide.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio import SeqIO\n",
        "from rdkit.Chem import Descriptors, MolFromSmiles\n",
        "from rdkit import Chem\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "from Bio import SeqIO\n",
        "\n",
        "def extract_ifeatures(input_file: str):\n",
        "    feature_types = ['AAC', 'DPC', 'CTDC', 'CTDD', 'CTDT']\n",
        "    feature_dfs = []\n",
        "\n",
        "    for feature_type in feature_types:\n",
        "        csv_output_file = f\"{os.path.splitext(input_file)[0]}_{feature_type.lower()}.csv\"\n",
        "        command = f\"python3 /content/iFeature/iFeature.py --file {input_file} --type {feature_type} --out {csv_output_file}\"\n",
        "        subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "        try:\n",
        "            feature_df = pd.read_csv(csv_output_file, header=0, index_col=False, sep=\"\\t\")\n",
        "        except pd.errors.ParserError:\n",
        "            feature_df = pd.read_csv(csv_output_file, header=0, index_col=False, sep=\",\")\n",
        "\n",
        "        feature_dfs.append(feature_df)\n",
        "        os.remove(csv_output_file)\n",
        "\n",
        "    final_df = feature_dfs[0]\n",
        "    for df in feature_dfs[1:]:\n",
        "        final_df = pd.merge(final_df, df, how='inner', left_on=final_df.columns[0], right_on=df.columns[0])\n",
        "\n",
        "    final_df = final_df.drop(columns=[final_df.columns[0]])\n",
        "    return final_df\n",
        "\n",
        "def extract_peptide_descriptors(input_fasta):\n",
        "    sequences = [str(record.seq) for record in SeqIO.parse(input_fasta, \"fasta\")]\n",
        "    all_descriptors = pd.DataFrame()\n",
        "\n",
        "    for sequence in sequences:\n",
        "        try:\n",
        "            # Convert peptide sequence to SMILES string\n",
        "            smiles_string = Chem.MolToSmiles(Chem.MolFromSequence(sequence))\n",
        "            mol = MolFromSmiles(smiles_string)\n",
        "\n",
        "            # Calculate RDKit descriptors\n",
        "            desc_values = {desc_name: descriptor(mol) if mol else None\n",
        "                           for desc_name, descriptor in Descriptors._descList}\n",
        "            all_descriptors = pd.concat([all_descriptors, pd.DataFrame(desc_values, index=[0])], ignore_index=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sequence {sequence}: {e}\")\n",
        "\n",
        "    return all_descriptors\n",
        "\n",
        "def generate_protparam_features(fasta_file):\n",
        "    peptides = [str(record.seq) for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
        "    results = []\n",
        "\n",
        "    for peptide in peptides:\n",
        "        analysis = ProteinAnalysis(peptide)\n",
        "        results.append({\n",
        "            'Number of Amino Acids': len(peptide),\n",
        "            'Molecular Weight': analysis.molecular_weight(),\n",
        "            'Aromaticity': analysis.aromaticity(),\n",
        "            'GRAVY': analysis.gravy(),\n",
        "            'Isoelectric Point': analysis.isoelectric_point(),\n",
        "            'Charge at pH 7': analysis.charge_at_pH(pH=7),\n",
        "            'Alpha-Helix Fraction': analysis.secondary_structure_fraction()[0],\n",
        "            'Beta-Sheet Fraction': analysis.secondary_structure_fraction()[2],\n",
        "            'Coil Fraction': analysis.secondary_structure_fraction()[1],\n",
        "            'Molar Extinction Coefficient (Reduced Cysteines)': analysis.molar_extinction_coefficient()[0],\n",
        "            'Molar Extinction Coefficient (Oxidized Cysteines)': analysis.molar_extinction_coefficient()[1]\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def calculate_atomic_composition(fasta_file):\n",
        "    def atomic_composition(protein):\n",
        "        atomic_weights = {\n",
        "            'A': (3, 7, 2, 1, 0), 'R': (6, 14, 2, 4, 0), 'N': (4, 8, 3, 2, 0), 'D': (4, 7, 4, 1, 0),\n",
        "            'C': (3, 7, 2, 1, 1), 'Q': (5, 10, 3, 2, 0), 'E': (5, 9, 4, 1, 0), 'G': (2, 5, 2, 1, 0),\n",
        "            'H': (6, 9, 2, 3, 0), 'I': (6, 13, 2, 1, 0), 'L': (6, 13, 2, 1, 0), 'K': (6, 14, 2, 2, 0),\n",
        "            'M': (5, 11, 2, 1, 1), 'F': (9, 11, 2, 1, 0), 'P': (5, 9, 2, 1, 0), 'S': (3, 7, 3, 1, 0),\n",
        "            'T': (4, 9, 3, 1, 0), 'W': (11, 12, 2, 2, 0), 'Y': (9, 11, 3, 1, 0), 'V': (5, 11, 2, 1, 0)\n",
        "        }\n",
        "        c = h = o = n = s = 0\n",
        "        for aa in protein:\n",
        "            if aa in atomic_weights:\n",
        "                c_add, h_add, o_add, n_add, s_add = atomic_weights[aa]\n",
        "                c += c_add; h += h_add; o += o_add; n += n_add; s += s_add\n",
        "        return c, h, o, n, s\n",
        "\n",
        "    results = []\n",
        "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        sequence = str(record.seq)\n",
        "        composition = atomic_composition(sequence)\n",
        "        results.append(list(composition))\n",
        "\n",
        "    return pd.DataFrame(results, columns=[\"C\", \"H\", \"O\", \"N\", \"S\"])\n",
        "\n",
        "def generate_combined_features(input_fasta):\n",
        "    # Extract individual features\n",
        "    feature_df1 = extract_ifeatures(input_fasta)\n",
        "    feature_df2 = extract_peptide_descriptors(input_fasta)  # This is the corrected line\n",
        "    feature_df3 = generate_protparam_features(input_fasta)\n",
        "    feature_df4 = calculate_atomic_composition(input_fasta)\n",
        "\n",
        "    # Merge the feature dataframes\n",
        "    final_df = pd.concat([feature_df1, feature_df2, feature_df3, feature_df4], axis=1)\n",
        "\n",
        "    # Save the final combined dataframe to an Excel file\n",
        "    base_name = os.path.splitext(os.path.basename(input_fasta))[0]\n",
        "    output_file = f\"{base_name}_combinedfeatures.xlsx\"\n",
        "    final_df.to_excel(output_file, index=False)\n",
        "\n",
        "    print(f\"Combined features saved to {output_file}\")\n",
        "\n",
        "# Example usage:\n",
        "generate_combined_features(\"peptide.fasta\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zAJF-mDL_5K",
        "outputId": "6a9e2e5d-a183-425a-a768-f59bccf5822f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined features saved to peptide_combinedfeatures.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def filter_columns_by_headers(file_path, headers_to_keep, output_file):\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: File not found at '{file_path}'.\")\n",
        "        return\n",
        "\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Retain only the columns in the provided list\n",
        "    filtered_df = df[headers_to_keep]\n",
        "\n",
        "    # Save the filtered DataFrame to a new Excel file\n",
        "    filtered_df.to_excel(output_file, index=False)\n",
        "    print(f\"Filtered file saved as: {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"peptide_combinedfeatures.xlsx\"  # Correct your file path\n",
        "\n",
        "headers_to_keep = ['Number of Amino Acids', 'Molecular Weight', 'Aromaticity', 'Isoelectric Point', 'Charge at pH 7', 'Alpha-Helix Fraction', 'Beta-Sheet Fraction', 'Coil Fraction', 'Molar Extinction Coefficient (Reduced Cysteines)', 'Molar Extinction Coefficient (Oxidized Cysteines)', 'C', 'H', 'O', 'N', 'S', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA4', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SlogP_VSA1', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA8', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_Ar_COO', 'fr_Ar_N', 'fr_C_O', 'fr_C_O_noCOO', 'fr_NH1', 'fr_NH2', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_benzene', 'fr_ester', 'fr_guanido', 'fr_nitro', 'fr_nitro_arom', 'fr_sulfide', 'fr_sulfonamd', 'A', 'C.1', 'D', 'E', 'F', 'G', 'H.1', 'I', 'K', 'L', 'M', 'N.1', 'P', 'Q', 'R', 'S.1', 'T', 'V', 'W', 'Y', 'AK', 'AV', 'AW', 'CA', 'CC', 'CE', 'CG', 'CR', 'CS', 'CT', 'CV', 'CY', 'DC', 'DG', 'DY', 'EC', 'EI', 'ER', 'FI', 'FK', 'FL', 'GC', 'GG', 'GR', 'GS', 'GW', 'HC', 'IF', 'IR', 'IY', 'KA', 'KI', 'KK', 'KL', 'KV', 'KW', 'LA', 'LC', 'LF', 'LK', 'LL', 'LR', 'MF', 'MK', 'MS', 'MV', 'NI', 'NR', 'PC', 'PE', 'PG', 'RC', 'RG', 'RM', 'RP', 'RR', 'RW', 'SE', 'SG', 'SI', 'SN', 'ST', 'VA', 'VT', 'WK', 'WQ', 'WR', 'YG', 'YQ', 'YS', 'hydrophobicity_PRAM900101.G1', 'hydrophobicity_PRAM900101.G2', 'hydrophobicity_PRAM900101.G3', 'hydrophobicity_ARGP820101.G1', 'hydrophobicity_ARGP820101.G2', 'hydrophobicity_ARGP820101.G3', 'hydrophobicity_ZIMJ680101.G1', 'hydrophobicity_ZIMJ680101.G2', 'hydrophobicity_ZIMJ680101.G3', 'hydrophobicity_PONP930101.G1', 'hydrophobicity_PONP930101.G2', 'hydrophobicity_PONP930101.G3', 'hydrophobicity_CASG920101.G1', 'hydrophobicity_CASG920101.G2', 'hydrophobicity_CASG920101.G3', 'hydrophobicity_ENGD860101.G1', 'hydrophobicity_ENGD860101.G2', 'hydrophobicity_ENGD860101.G3', 'hydrophobicity_FASG890101.G1', 'hydrophobicity_FASG890101.G2', 'hydrophobicity_FASG890101.G3', 'normwaalsvolume.G1', 'normwaalsvolume.G2', 'normwaalsvolume.G3', 'polarity.G1', 'polarity.G2', 'polarity.G3', 'polarizability.G1', 'polarizability.G2', 'polarizability.G3', 'charge.G1', 'charge.G2', 'charge.G3', 'secondarystruct.G1', 'secondarystruct.G2', 'secondarystruct.G3', 'solventaccess.G1', 'solventaccess.G2', 'solventaccess.G3', 'hydrophobicity_PRAM900101.1.residue0', 'hydrophobicity_PRAM900101.1.residue25', 'hydrophobicity_PRAM900101.1.residue50', 'hydrophobicity_PRAM900101.1.residue75', 'hydrophobicity_PRAM900101.1.residue100', 'hydrophobicity_PRAM900101.2.residue0', 'hydrophobicity_PRAM900101.2.residue25', 'hydrophobicity_PRAM900101.2.residue50', 'hydrophobicity_PRAM900101.2.residue75', 'hydrophobicity_PRAM900101.2.residue100', 'hydrophobicity_PRAM900101.3.residue0', 'hydrophobicity_PRAM900101.3.residue25', 'hydrophobicity_PRAM900101.3.residue50', 'hydrophobicity_PRAM900101.3.residue75', 'hydrophobicity_PRAM900101.3.residue100', 'hydrophobicity_ARGP820101.1.residue0', 'hydrophobicity_ARGP820101.1.residue25', 'hydrophobicity_ARGP820101.1.residue50', 'hydrophobicity_ARGP820101.1.residue75', 'hydrophobicity_ARGP820101.1.residue100', 'hydrophobicity_ARGP820101.2.residue0', 'hydrophobicity_ARGP820101.2.residue25', 'hydrophobicity_ARGP820101.2.residue50', 'hydrophobicity_ARGP820101.2.residue75', 'hydrophobicity_ARGP820101.2.residue100', 'hydrophobicity_ARGP820101.3.residue0', 'hydrophobicity_ARGP820101.3.residue25', 'hydrophobicity_ARGP820101.3.residue50', 'hydrophobicity_ARGP820101.3.residue75', 'hydrophobicity_ARGP820101.3.residue100', 'hydrophobicity_ZIMJ680101.1.residue0', 'hydrophobicity_ZIMJ680101.1.residue25', 'hydrophobicity_ZIMJ680101.1.residue50', 'hydrophobicity_ZIMJ680101.1.residue75', 'hydrophobicity_ZIMJ680101.1.residue100', 'hydrophobicity_ZIMJ680101.2.residue0', 'hydrophobicity_ZIMJ680101.2.residue25', 'hydrophobicity_ZIMJ680101.2.residue50', 'hydrophobicity_ZIMJ680101.2.residue75', 'hydrophobicity_ZIMJ680101.2.residue100', 'hydrophobicity_ZIMJ680101.3.residue0', 'hydrophobicity_ZIMJ680101.3.residue25', 'hydrophobicity_ZIMJ680101.3.residue50', 'hydrophobicity_ZIMJ680101.3.residue75', 'hydrophobicity_ZIMJ680101.3.residue100', 'hydrophobicity_PONP930101.1.residue0', 'hydrophobicity_PONP930101.1.residue25', 'hydrophobicity_PONP930101.1.residue50', 'hydrophobicity_PONP930101.1.residue75', 'hydrophobicity_PONP930101.1.residue100', 'hydrophobicity_PONP930101.2.residue0', 'hydrophobicity_PONP930101.2.residue25', 'hydrophobicity_PONP930101.2.residue50', 'hydrophobicity_PONP930101.2.residue75', 'hydrophobicity_PONP930101.2.residue100', 'hydrophobicity_PONP930101.3.residue0', 'hydrophobicity_PONP930101.3.residue25', 'hydrophobicity_PONP930101.3.residue50', 'hydrophobicity_PONP930101.3.residue75', 'hydrophobicity_PONP930101.3.residue100', 'hydrophobicity_CASG920101.1.residue0', 'hydrophobicity_CASG920101.1.residue25', 'hydrophobicity_CASG920101.1.residue50', 'hydrophobicity_CASG920101.1.residue75', 'hydrophobicity_CASG920101.1.residue100', 'hydrophobicity_CASG920101.2.residue0', 'hydrophobicity_CASG920101.2.residue25', 'hydrophobicity_CASG920101.2.residue50', 'hydrophobicity_CASG920101.2.residue75', 'hydrophobicity_CASG920101.2.residue100', 'hydrophobicity_CASG920101.3.residue0', 'hydrophobicity_CASG920101.3.residue25', 'hydrophobicity_CASG920101.3.residue50', 'hydrophobicity_CASG920101.3.residue75', 'hydrophobicity_CASG920101.3.residue100', 'hydrophobicity_ENGD860101.1.residue0', 'hydrophobicity_ENGD860101.1.residue25', 'hydrophobicity_ENGD860101.1.residue50', 'hydrophobicity_ENGD860101.1.residue75', 'hydrophobicity_ENGD860101.1.residue100', 'hydrophobicity_ENGD860101.2.residue0', 'hydrophobicity_ENGD860101.2.residue25', 'hydrophobicity_ENGD860101.2.residue50', 'hydrophobicity_ENGD860101.2.residue75', 'hydrophobicity_ENGD860101.2.residue100', 'hydrophobicity_ENGD860101.3.residue0', 'hydrophobicity_ENGD860101.3.residue25', 'hydrophobicity_ENGD860101.3.residue50', 'hydrophobicity_ENGD860101.3.residue75', 'hydrophobicity_ENGD860101.3.residue100', 'hydrophobicity_FASG890101.1.residue0', 'hydrophobicity_FASG890101.1.residue25', 'hydrophobicity_FASG890101.1.residue50', 'hydrophobicity_FASG890101.1.residue75', 'hydrophobicity_FASG890101.1.residue100', 'hydrophobicity_FASG890101.2.residue0', 'hydrophobicity_FASG890101.2.residue25', 'hydrophobicity_FASG890101.2.residue50', 'hydrophobicity_FASG890101.2.residue75', 'hydrophobicity_FASG890101.2.residue100', 'hydrophobicity_FASG890101.3.residue0', 'hydrophobicity_FASG890101.3.residue25', 'hydrophobicity_FASG890101.3.residue50', 'hydrophobicity_FASG890101.3.residue75', 'hydrophobicity_FASG890101.3.residue100', 'normwaalsvolume.1.residue0', 'normwaalsvolume.1.residue25', 'normwaalsvolume.1.residue50', 'normwaalsvolume.1.residue75', 'normwaalsvolume.1.residue100', 'normwaalsvolume.2.residue0', 'normwaalsvolume.2.residue25', 'normwaalsvolume.2.residue50', 'normwaalsvolume.2.residue75', 'normwaalsvolume.2.residue100', 'normwaalsvolume.3.residue0', 'normwaalsvolume.3.residue25', 'normwaalsvolume.3.residue50', 'normwaalsvolume.3.residue75', 'normwaalsvolume.3.residue100', 'polarity.1.residue0', 'polarity.1.residue25', 'polarity.1.residue50', 'polarity.1.residue75', 'polarity.1.residue100', 'polarity.2.residue0', 'polarity.2.residue25', 'polarity.2.residue50', 'polarity.2.residue75', 'polarity.2.residue100', 'polarity.3.residue0', 'polarity.3.residue25', 'polarity.3.residue50', 'polarity.3.residue75', 'polarity.3.residue100', 'polarizability.1.residue0', 'polarizability.1.residue25', 'polarizability.1.residue50', 'polarizability.1.residue75', 'polarizability.1.residue100', 'polarizability.2.residue0', 'polarizability.2.residue25', 'polarizability.2.residue50', 'polarizability.2.residue75', 'polarizability.2.residue100', 'polarizability.3.residue0', 'polarizability.3.residue25', 'polarizability.3.residue50', 'polarizability.3.residue75', 'polarizability.3.residue100', 'charge.1.residue0', 'charge.1.residue25', 'charge.1.residue50', 'charge.1.residue75', 'charge.1.residue100', 'charge.2.residue0', 'charge.2.residue25', 'charge.2.residue50', 'charge.2.residue75', 'charge.2.residue100', 'charge.3.residue0', 'charge.3.residue25', 'charge.3.residue50', 'charge.3.residue75', 'charge.3.residue100', 'secondarystruct.1.residue0', 'secondarystruct.1.residue25', 'secondarystruct.1.residue50', 'secondarystruct.1.residue75', 'secondarystruct.1.residue100', 'secondarystruct.2.residue0', 'secondarystruct.2.residue25', 'secondarystruct.2.residue50', 'secondarystruct.2.residue75', 'secondarystruct.2.residue100', 'secondarystruct.3.residue0', 'secondarystruct.3.residue25', 'secondarystruct.3.residue50', 'secondarystruct.3.residue75', 'secondarystruct.3.residue100', 'solventaccess.1.residue0', 'solventaccess.1.residue25', 'solventaccess.1.residue50', 'solventaccess.1.residue75', 'solventaccess.1.residue100', 'solventaccess.2.residue0', 'solventaccess.2.residue25', 'solventaccess.2.residue50', 'solventaccess.2.residue75', 'solventaccess.2.residue100', 'solventaccess.3.residue0', 'solventaccess.3.residue25', 'solventaccess.3.residue50', 'solventaccess.3.residue75', 'solventaccess.3.residue100', 'hydrophobicity_PRAM900101.Tr1221', 'hydrophobicity_PRAM900101.Tr1331', 'hydrophobicity_PRAM900101.Tr2332', 'hydrophobicity_ARGP820101.Tr1221', 'hydrophobicity_ARGP820101.Tr1331', 'hydrophobicity_ARGP820101.Tr2332', 'hydrophobicity_ZIMJ680101.Tr1221', 'hydrophobicity_ZIMJ680101.Tr1331', 'hydrophobicity_ZIMJ680101.Tr2332', 'hydrophobicity_PONP930101.Tr1221', 'hydrophobicity_PONP930101.Tr1331', 'hydrophobicity_PONP930101.Tr2332', 'hydrophobicity_CASG920101.Tr1221', 'hydrophobicity_CASG920101.Tr1331', 'hydrophobicity_CASG920101.Tr2332', 'hydrophobicity_ENGD860101.Tr1221', 'hydrophobicity_ENGD860101.Tr1331', 'hydrophobicity_ENGD860101.Tr2332', 'hydrophobicity_FASG890101.Tr1221', 'hydrophobicity_FASG890101.Tr1331', 'hydrophobicity_FASG890101.Tr2332', 'normwaalsvolume.Tr1221', 'normwaalsvolume.Tr1331', 'normwaalsvolume.Tr2332', 'polarity.Tr1221', 'polarity.Tr1331', 'polarity.Tr2332', 'polarizability.Tr1221', 'polarizability.Tr1331', 'polarizability.Tr2332', 'charge.Tr1221', 'charge.Tr1331', 'charge.Tr2332', 'secondarystruct.Tr1221', 'secondarystruct.Tr1331', 'secondarystruct.Tr2332', 'solventaccess.Tr1221', 'solventaccess.Tr1331', 'solventaccess.Tr2332']\n",
        "# Replace with the headers you want to retain\n",
        "output_file = \"peptide_eliminated.xlsx\"\n",
        "\n",
        "filter_columns_by_headers(file_path, headers_to_keep, output_file)\n",
        "print(f\"Selected features saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9K5GMK0Nz_n",
        "outputId": "82f9d592-3285-4444-a0cb-fa101593a8e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered file saved as: peptide_eliminated.xlsx\n",
            "Selected features saved to peptide_eliminated.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def filter_columns_by_headers(file_path, headers_to_keep, output_file):\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: File not found at '{file_path}'.\")\n",
        "        return\n",
        "\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Retain only the columns in the provided list\n",
        "    filtered_df = df[headers_to_keep]\n",
        "\n",
        "    # Save the filtered DataFrame to a new Excel file\n",
        "    filtered_df.to_excel(output_file, index=False)\n",
        "    print(f\"Filtered file saved as: {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"peptide_eliminated.xlsx\"  # Correct your file path\n",
        "headers_to_keep = ['SPS', 'FpDensityMorgan1', 'FpDensityMorgan2', 'BCUT2D_MWLOW', 'BCUT2D_CHGLO', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'Chi1', 'Chi2n', 'Chi2v', 'Kappa2', 'Kappa3', 'PEOE_VSA6', 'PEOE_VSA7', 'SMR_VSA4', 'SMR_VSA5', 'SlogP_VSA1', 'SlogP_VSA4', 'SlogP_VSA5', 'EState_VSA10', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA9', 'VSA_EState2', 'VSA_EState4', 'FractionCSP3', 'NumRotatableBonds', 'MolLogP', 'fr_NH2', 'A', 'C.1', 'D', 'E', 'F', 'G', 'H.1', 'I', 'K', 'L', 'M', 'N.1', 'P', 'Q', 'R', 'S.1', 'T', 'V', 'W', 'Y', 'hydrophobicity_PRAM900101.G1', 'hydrophobicity_PRAM900101.G2', 'hydrophobicity_PONP930101.G1', 'hydrophobicity_PONP930101.G3', 'hydrophobicity_CASG920101.G3', 'normwaalsvolume.G1', 'solventaccess.G3', 'hydrophobicity_PRAM900101.3.residue75', 'hydrophobicity_ARGP820101.3.residue0', 'hydrophobicity_ZIMJ680101.1.residue50', 'hydrophobicity_ZIMJ680101.1.residue75', 'hydrophobicity_ZIMJ680101.1.residue100', 'hydrophobicity_PONP930101.2.residue25', 'hydrophobicity_PONP930101.3.residue25', 'hydrophobicity_PONP930101.3.residue50', 'hydrophobicity_PONP930101.3.residue75', 'hydrophobicity_PONP930101.3.residue100', 'hydrophobicity_CASG920101.3.residue0', 'hydrophobicity_CASG920101.3.residue25', 'hydrophobicity_CASG920101.3.residue50', 'hydrophobicity_CASG920101.3.residue100', 'hydrophobicity_ENGD860101.2.residue100', 'hydrophobicity_ENGD860101.3.residue0', 'hydrophobicity_ENGD860101.3.residue50', 'hydrophobicity_ENGD860101.3.residue75', 'hydrophobicity_FASG890101.3.residue0', 'polarity.1.residue75', 'polarity.1.residue100', 'polarizability.1.residue0', 'charge.1.residue75', 'charge.2.residue75', 'secondarystruct.2.residue75', 'secondarystruct.3.residue75', 'solventaccess.1.residue50', 'solventaccess.1.residue75', 'solventaccess.2.residue0', 'hydrophobicity_PRAM900101.Tr1331', 'hydrophobicity_PRAM900101.Tr2332', 'hydrophobicity_ARGP820101.Tr2332', 'hydrophobicity_PONP930101.Tr1331', 'hydrophobicity_PONP930101.Tr2332', 'hydrophobicity_CASG920101.Tr1221', 'hydrophobicity_CASG920101.Tr2332', 'hydrophobicity_ENGD860101.Tr2332', 'hydrophobicity_FASG890101.Tr1331', 'normwaalsvolume.Tr1331', 'normwaalsvolume.Tr2332', 'polarity.Tr1331', 'polarizability.Tr2332', 'secondarystruct.Tr1221']# Replace with the headers you want to retain\n",
        "output_file = \"peptide.xlsx\"\n",
        "\n",
        "filter_columns_by_headers(file_path, headers_to_keep, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "891y_zgHOMC4",
        "outputId": "13e2f316-0caa-4f25-bc69-c88e1ed013ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered file saved as: peptide.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax-hRZY2kmM9",
        "outputId": "b3fe7f72-a08e-4c91-f75e-2f7a97f27932"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.6.1\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.5.0)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.4.2\n",
            "    Uninstalling scikit-learn-1.4.2:\n",
            "      Successfully uninstalled scikit-learn-1.4.2\n",
            "Successfully installed scikit-learn-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading models"
      ],
      "metadata": {
        "id": "uIaN2wHDYjGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "gnb = joblib.load(\"gnb_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "scaler_rf = joblib.load(\"scaler_rf.pkl\")\n",
        "ab_model = joblib.load(\"adaboost_model.pkl\")\n",
        "scaler_ab = joblib.load(\"scaler_ab.pkl\")\n",
        "et_model = joblib.load(\"extratrees_model.pkl\")\n",
        "scaler_et = joblib.load(\"scaler_et.pkl\")"
      ],
      "metadata": {
        "id": "ca8tXtBhYlHO",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EnhancedANN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(EnhancedANN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Define the model path\n",
        "model_path = \"ann_model.pth\"  # Ensure this is the correct path\n",
        "\n",
        "input_dim = 100\n",
        "\n",
        "# Initialize the model\n",
        "ann_model = EnhancedANN(input_dim)\n",
        "\n",
        "# Load the saved model weights\n",
        "ann_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "ann_model.eval()\n",
        "\n",
        "print(\"Model successfully loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2axwumHBdZSF",
        "outputId": "99fb5975-fe65-4343-f35a-a5d788a98e29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully loaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-629479f3878c>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ann_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channels, input_dim):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Define the model path in Google Drive\n",
        "model_path = \"cnn_model.pth\"  # Adjust the path as needed\n",
        "\n",
        "# Specify the input dimensions (must match the trained model's input)\n",
        "input_channels = 1\n",
        "input_dim = 100  # Replace with the actual number of features used during training\n",
        "\n",
        "# Initialize the model with the correct input shape\n",
        "cnn_model = CNN(input_channels, input_dim)\n",
        "\n",
        "# Load the saved weights\n",
        "cnn_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "cnn_model.eval()  # Set model to evaluation mode\n",
        "\n",
        "print(\"Model successfully loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fulas0GPc-SO",
        "outputId": "3fbda65c-6265-4911-c9d1-2735c1f6c978"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully loaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-b057b951654a>:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cnn_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction using various models"
      ],
      "metadata": {
        "id": "FxPRkyVMgxCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"peptide.xlsx\")"
      ],
      "metadata": {
        "id": "lJ7-dthMg8_j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_gnb = df.values\n",
        "gnb_prob = gnb.predict_proba(X_gnb)[:, 1]  # Probability of class 1\n",
        "gnb_pred = gnb.predict(X_gnb)\n",
        "print(\"Predictions from Gaussian Naive Bayes:\", gnb_pred)\n",
        "\n",
        "X_rf = scaler_rf.transform(df)\n",
        "rf_prob = rf_model.predict_proba(X_rf)[:, 1]\n",
        "rf_pred = rf_model.predict(X_rf)\n",
        "print(\"Predictions from Random Forest:\", rf_pred)\n",
        "\n",
        "\n",
        "X_ab = scaler_ab.transform(df)\n",
        "ab_prob = ab_model.predict_proba(X_ab)[:, 1]\n",
        "ab_pred = ab_model.predict(X_ab)\n",
        "print(\"Predictions from AdaBoost:\", ab_pred)\n",
        "\n",
        "\n",
        "X_et = scaler_et.transform(df)\n",
        "et_prob = et_model.predict_proba(X_et)[:, 1]\n",
        "et_pred = et_model.predict(X_et)\n",
        "print(\"Predictions from Extra Trees:\", et_pred)\n",
        "\n",
        "X_ann = torch.tensor(df.values, dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    ann_prob = ann_model(X_ann).numpy().flatten()  # Already sigmoid output\n",
        "ann_pred = (ann_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"Predictions from ANN:\", ann_pred.flatten())\n",
        "\n",
        "\n",
        "X_cnn = torch.tensor(df.values, dtype=torch.float32).unsqueeze(1)\n",
        "with torch.no_grad():\n",
        "    cnn_prob = cnn_model(X_cnn).numpy().flatten()  # Already sigmoid output\n",
        "cnn_pred = (cnn_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"Predictions from CNN:\", cnn_pred.flatten())\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "\n",
        "pred_ann = ann_pred\n",
        "pred_cnn = cnn_pred\n",
        "pred_gnb = gnb_pred\n",
        "pred_rf = rf_pred\n",
        "pred_ab = ab_pred\n",
        "pred_et = et_pred\n",
        "\n",
        "prob_ann = ann_prob\n",
        "prob_cnn = cnn_prob\n",
        "prob_gnb = gnb_prob\n",
        "prob_rf = rf_prob\n",
        "prob_ab = ab_prob\n",
        "prob_et = et_prob\n",
        "\n",
        "predictions = np.vstack([pred_ann, pred_cnn, pred_gnb, pred_rf, pred_ab, pred_et])\n",
        "\n",
        "\n",
        "final_pred, _ = mode(predictions, axis=0)\n",
        "final_pred = final_pred.flatten()\n",
        "\n",
        "probabilities = np.vstack([prob_ann, prob_cnn, prob_gnb, prob_rf, prob_ab, prob_et])\n",
        "\n",
        "final_prob = np.mean(probabilities, axis=0)\n",
        "\n",
        "for i in range(len(final_pred)):\n",
        "    if final_pred[i] == 1:\n",
        "        print(f\"Sample {i+1}: ABCP (Probability: {final_prob[i]:.4f})\")\n",
        "    else:\n",
        "        print(f\"Sample {i+1}: NON-ABCP (Probability: {final_prob[i]:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Evkmgr0if6KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b077dc06-f2ac-4ed4-b752-2e6d5a1a3434"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from Gaussian Naive Bayes: [1]\n",
            "Predictions from Random Forest: [1]\n",
            "Predictions from AdaBoost: [0]\n",
            "Predictions from Extra Trees: [1]\n",
            "Predictions from ANN: [1]\n",
            "Predictions from CNN: [1]\n",
            "Sample 1: ABCP (Probability: 0.7690)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}